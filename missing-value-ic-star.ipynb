{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IC* Algorithm with Missing Data\n",
    "\n",
    "SkeletonFinder\n",
    "\n",
    "PairwiseConditionalIndependenceTester\n",
    "    - variables to compare\n",
    "    - conditioning set\n",
    "    \n",
    "    independent(cutoff?): boolean\n",
    "\n",
    "ImmoralitiesFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSplitter\n",
    "\n",
    "DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConditionalIndependenceTester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ 'hello': ['a','b','c'], 'hi': ['1', '2', '3']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionallyIndependentDataGenerator:\n",
    "    \"\"\"\n",
    "        @param data [pandas.DataFrame] Part of the columns are the conditioning_set_names \n",
    "            and swappables as columns. \n",
    "        \n",
    "        @param swappables [List[String]] The variable we're copying from half of the data \n",
    "        set.\n",
    "        \n",
    "        @param conditioning_set_names [List[String]] List of String names of what we're \n",
    "        conditioning on (i.e. Z in the example above). Defaults to empty list.\n",
    "        \n",
    "        Main idea is to generate a data set that satisfies X _||_ Y | Z: X is independent of\n",
    "        Y given Z, which is satisfied if f(x|z)f(y|z)f(z) = f(x,y,z). We're able to do this\n",
    "        by splitting the data set into two. For the first data set, find the 1-Nearest \n",
    "        Neighbors from the second data set using z. Then pick the Y from the second data set \n",
    "        and set that as the new Y for the first data set. This amounts to sampling f(y | z).\n",
    "        We already have f(x|z) and f(z) in the first data set, so by returning the first data \n",
    "        set, we have f(x|z)f(y|z)f(z) = f(x,y,z).\n",
    "    \"\"\"\n",
    "    def __init__(self, data, swappables, conditioning_set_names=[]):\n",
    "        self.swappables = swappables\n",
    "        self.conditioning_set_names = conditioning_set_names\n",
    "        self.data = data\n",
    "        \n",
    "        half_length = int(data.shape[0] / 2)\n",
    "            \n",
    "        self.data_1 = data.iloc[:half_length].copy()\n",
    "        self.data_2 = data.iloc[half_length:self.__end_index__()].copy()\n",
    "        \n",
    "        assert len(swappables) >= 1\n",
    "        assert self.data_1.shape[0] == self.data_2.shape[0]\n",
    "        \n",
    "\n",
    "    def generate(self):\n",
    "        \"\"\"\n",
    "            Generates a conditionally independent data set.\n",
    "\n",
    "            @return [pandas.DataFrame] DataFrame with half the length of the original data passed in\n",
    "            the init method.\n",
    "        \"\"\"\n",
    "        columns = self.data_1.columns \n",
    "        not_swappables = list(set(columns) - set(self.swappables))\n",
    "            \n",
    "        if len(self.conditioning_set_names) == 0:\n",
    "            # shuffle the swappable part to break dependence between \"swappable\" and \n",
    "            # \"not swappable\" columns\n",
    "            \n",
    "            return pd.concat(\n",
    "                [\n",
    "                    self.data_1[not_swappables].reset_index(drop=True),\n",
    "                    self.data_1[self.swappables]\\\n",
    "                        .sample(n=self.data_1.shape[0]).reset_index(drop=True)\n",
    "                ],\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "        data_1_cond_set = self.data_1[self.conditioning_set_names].copy()\n",
    "        data_2_cond_set = self.data_2[self.conditioning_set_names].copy()\n",
    "    \n",
    "        nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').\\\n",
    "            fit(data_1_cond_set.values)\n",
    "        \n",
    "        _, indices = nbrs.kneighbors(data_2_cond_set.values)\n",
    "        \n",
    "        data_2_nearest_neighbors = self.data_2.iloc[indices.reshape(1, indices.shape[0])[0]]\n",
    "        \n",
    "        data_1_concatables = self.data_1[not_swappables]\n",
    "        data_2_concatables = data_2_nearest_neighbors[self.swappables]\n",
    "        \n",
    "        return pd.concat(\n",
    "            [\n",
    "                data_1_concatables.reset_index(drop=True),\n",
    "                data_2_concatables.reset_index(drop=True)\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    def __end_index__(self):\n",
    "        \"\"\"\n",
    "            Meant to help enforce equal sizes for the two data sets to make later steps \n",
    "            (e.g swapping) easier.\n",
    "        \"\"\"\n",
    "        if self.data.shape[0] % 2 != 0:\n",
    "            return self.data.shape[0] - 1\n",
    "        else: \n",
    "            return self.data.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalIndependenceTester:\n",
    "    \"\"\"\n",
    "        @param data [pandas.DataFrame] \n",
    "        @param comparables_1 [List[Strings]] List of variable names.\n",
    "        @param comparables_2 [List[Strings]] List of variable names.\n",
    "        @param conditioning_set = [List[Strings]] The list of variable names \n",
    "            corresponding to the conditioning set.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, comparables_1, comparables_2, conditioning_set=[]):\n",
    "        self.data = data\n",
    "        self.comparables_1 = comparables_1\n",
    "        self.comparables_2 = comparables_2\n",
    "        self.conditioning_set = conditioning_set\n",
    "        \n",
    "        assert len(self.comparables_1) >= 1\n",
    "        assert len(self.comparables_2) >= 1\n",
    "        \n",
    "\n",
    "    def is_independent(self):\n",
    "        \"\"\"\n",
    "            Tests the conditional independence X _||_ Y | Z.\n",
    "\n",
    "            X represents comparables_1 param (passed in to the init method).\n",
    "            Y represents comparables_2 param (passed in to the init method).\n",
    "            Z represents the conditioning_set (passed in to the init method).\n",
    "                Could be empty.\n",
    "\n",
    "            @return boolean\n",
    "        \"\"\"\n",
    "        data_1_length = int(self.data.shape[0] / 3)\n",
    "        data_1 = self.data.iloc[0:data_1_length].copy()\n",
    "        data_2 = self.data.iloc[data_1_length:]\n",
    "        \n",
    "        cid_generator = ConditionallyIndependentDataGenerator(\n",
    "            data=data_2, \n",
    "            swappables=self.comparables_2\n",
    "        )\n",
    "        \n",
    "        conditionally_indep_data = cid_generator.generate()\n",
    "        \n",
    "        data_1['label'] = 1\n",
    "        conditionally_indep_data['label'] = 0\n",
    "        \n",
    "        train_and_test_data = pd.concat([\n",
    "            data_1,\n",
    "            conditionally_indep_data\n",
    "        ])\n",
    "        \n",
    "        predictors = list(set(train_and_test_data.columns) - set(['label']))\n",
    "        \n",
    "        X = train_and_test_data[predictors].values\n",
    "        y = train_and_test_data['label']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.5, stratify=y\n",
    "        )\n",
    "        \n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "        return clf.score(X_test, y_test) <= 0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_independent(results):\n",
    "    \"\"\"\n",
    "        @param results [List[Boolean]] True if independent, False if dependent\n",
    "        \n",
    "        @return percent of true count / results count\n",
    "    \"\"\"\n",
    "    \n",
    "    return results.sum() / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_a_bunch(func, num_times=1000, size=1000):\n",
    "    results = []\n",
    "    \n",
    "    for i in range(num_times):\n",
    "        results.append(func(size))\n",
    "    \n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependent_two_vars(size=1000):\n",
    "    x = np.random.normal(size=size)\n",
    "    u = np.random.normal(size=size)\n",
    "    y = x + u\n",
    "    uncond_indep_df = pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "    tester = ConditionalIndependenceTester(data=uncond_indep_df, comparables_1=['x'], comparables_2=['y'])\n",
    "    return tester.is_independent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def independent_two_vars(size=1000):\n",
    "    x = np.random.normal(size=size)\n",
    "    y = np.random.normal(size=size)\n",
    "    df = pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "    tester = ConditionalIndependenceTester(data=df, comparables_1=['x'], comparables_2=['y'])\n",
    "    return tester.is_independent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cases:\n",
    "\n",
    "\n",
    "\n",
    "* $X \\perp Y | Z$\n",
    "    - fork\n",
    "    - chain\n",
    "    \n",
    "* $X \\not\\perp Y | Z$\n",
    "    - collider case\n",
    "    - fork with unobserved confounding\n",
    "    - chain with unobserved confounding\n",
    "\n",
    "* Variable type\n",
    "    - Discrete variables\n",
    "    - Continuous variables\n",
    "    - Mix of Discrete and Continuous variables\n",
    "\n",
    "* Positivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_independent(test_a_bunch(func=dependent_two_vars, size=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_independent(test_a_bunch(func=independent_two_vars, size=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_independent(test_a_bunch(func=dependent_two_vars, size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.917"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_independent(test_a_bunch(func=independent_two_vars, size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.415"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_independent(test_a_bunch(func=dependent_two_vars, size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.659"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_independent(test_a_bunch(func=independent_two_vars, size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_two_vars_results.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.normal(size=1000)\n",
    "y = np.random.normal(size=1000)\n",
    "uncond_indep_df = pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "tester = ConditionalIndependenceTester(data=uncond_indep_df, comparables_1=['x'], comparables_2=['y'])\n",
    "tester.is_independent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuclideanDistanceDataPreprocessor:\n",
    "    \"\"\"\n",
    "        @param data [pandas.DataFrame] \n",
    "            Each column represents data from a variable.  \n",
    "        @param continuous_var_names [List[String]]\n",
    "            Names of variables that are continuous.\n",
    "        @param multi_choice_categorical_var_names [List[String]]\n",
    "            Names of variables where each there could be multiple\n",
    "            values per row.\n",
    "                e.g. Race: Someone could be Black ([1 0]).\n",
    "                    Another could be Asian ([0 1]).\n",
    "                    And another could identify as being both Black & Asian ([1 1]).\n",
    "        @param single_choice_categorical_var_names [List[String]]\n",
    "            Names of variables. Makes sense when there's only one option \n",
    "            possible per category.\n",
    "                e.g. Height:\n",
    "                    - Under 5 ft.\n",
    "                    - Between 5 ft. and 6 ft.\n",
    "                    - Over 6 ft.\n",
    "                    \n",
    "        This class is meant to help prepare data for the ConditionalIndependenceTester \n",
    "        class, which uses Nearest Neighbor methods. Nearest Neighbor methods have a \n",
    "        notion of distance. We vectorize the data so we can do nearest neighbor methods\n",
    "        on them.\n",
    "        \n",
    "        This Preprocessor makes data amenable to nearest neighbor methods that use\n",
    "        the Euclidean distance as the distance metric.\n",
    "        \n",
    "        It does this by: \n",
    "        \n",
    "        1. Representing all columns as vectors of floats (i.e. no strings). \n",
    "        \n",
    "        2. Scaling the variables so that their effects on the distance \n",
    "            metric is about the same.\n",
    "\n",
    "        Here's the strategy that is being used here to implement that:\n",
    "        \n",
    "        For continuous data, we will scale the data between 0 and 1.\n",
    "        \n",
    "        For non-ordinal categorical data, there are two situations to consider:\n",
    "            - single-choice categorical columns\n",
    "            - multi-choice categorical columns\n",
    "         \n",
    "        For single-choice categorical columns, we could dummify / one-hot-encode \n",
    "        them. Once they are one-hot encoded, we could scale the\n",
    "        one-hot-encoding by 1/sqrt(2) so that categorical data weighs the \n",
    "        same as a continuous variable.\n",
    "        \n",
    "        For multi-choice categorical columns, we could dummify / one-hot-encode\n",
    "        them, just like we did for the single-choice categorical columns. \n",
    "        However, instead of scaling by 1/sqrt(2), we scale by some function that\n",
    "        takes into account the cardinality of the variable: 1/sqrt(m), where m\n",
    "        is the cardinality of the multi-choice variable. This scaling will make \n",
    "        multi-choice categorical columns be weighed the same as other types of \n",
    "        variables.\n",
    "        \n",
    "        Example:\n",
    "        \n",
    "        Single-choice example; Let's say there's a single-choice variable such as \n",
    "        a discretized version of Height (e.g. one could be below 5 feet, be between\n",
    "        5 feet and 6 feet, or be 6 feet and greater).\n",
    "        \n",
    "        In terms of the worst distance possible between two people, let's say\n",
    "        one individual identifies as below 5 feet, and another identifies\n",
    "        as above 6 feet. The former will be represented by:\n",
    "        \n",
    "            [1, 0, 0] * 1 / sqrt(2) = [0.707, 0, 0]\n",
    "        \n",
    "        While the latter will be represented by:\n",
    "        \n",
    "            [0, 0, 1] * 1 / sqrt(2) = [0, 0, 0.707]\n",
    "            \n",
    "        The Euclidean distance between the two would be sqrt(2(0.707-0)^2) = 1.\n",
    "            \n",
    "            \n",
    "        Multi-choice example: Let's say there's a multi-choice variable such as\n",
    "        Race is 3. In this contrived example, let's say that variable can take \n",
    "        one or more values in [Black, Asian, White].\n",
    "        \n",
    "        In terms of the worst distance possible between two people, let's say\n",
    "        one individual identifies as Black, Asian, and White, and another identifies\n",
    "        as none of those. The former will be represented by:\n",
    "        \n",
    "            [1, 1, 1] * 1 / sqrt(3) = [0.577, 0.577, 0.577]\n",
    "        \n",
    "        While the latter will be represented by:\n",
    "        \n",
    "            [0, 0, 0] * 1 / sqrt(3) = [0, 0, 0]\n",
    "            \n",
    "        The Euclidean distance between the two would be sqrt(3(0.577-0)^2) = 1.\n",
    "        \n",
    "        Finally, let's consider the continuous case. Let's say there's a variable called\n",
    "        Weight, which is some continuous variable between 10 & 300 pounds. Let's say that\n",
    "        one individual is 10 lbs and another is 300 lbs. The first individual will be\n",
    "        represented as 0, and the other as 1. So the Euclidean distance between the two is \n",
    "        \n",
    "            sqrt((1-0)^2)= 1\n",
    "            \n",
    "        As we can see from the two scenarios, the scaling factor enables us to make\n",
    "        each variable have the same impact on the Euclidean distance metric as other\n",
    "        variables, regardless of the variable being discrete or continuous.\n",
    "    \"\"\"\n",
    "    \n",
    "    SINGLE_CHOICE_SCALER = 0.707\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        data, \n",
    "        continuous_var_names, \n",
    "        multi_choice_categorical_var_names, \n",
    "        single_choice_categorical_var_names\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.continuous_var_names = continuous_var_names\n",
    "        self.multi_choice_categorical_var_names = \\\n",
    "            multi_choice_categorical_var_names\n",
    "        self.single_choice_categorical_var_names = \\\n",
    "            single_choice_categorical_var_names\\\n",
    "            \n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "            @return [pandas.DataFrame] where each row is a vector that is amenable to \n",
    "            computing the Euclidean distance between that and other rows.\n",
    "\n",
    "            For continuous variables, their names would stay the same (e.g. if \n",
    "            \"weight\" was passed in the list of continuous_var_names, then we would see\n",
    "            \"weight\" as a column name. Values would be scaled between 0 and 1.)\n",
    "\n",
    "            For single-choice categorical variables, their dummy-fied names would be \n",
    "            appended by the values (e.g. if there's a single-choice categorical \n",
    "            variable named \"favorite color\" and the possible answers are \"red\", \n",
    "            \"white\", and \"green\", then we will have three columns: \n",
    "                - \"favorite color | red\", \n",
    "                - \"favorite color | white\", and \n",
    "                - \"favorite color | green\"\n",
    "\n",
    "            For multi-choice categorical variables, their dummy-fied names would be \n",
    "            appended by the values (e.g. if there's a multi-choice categorical \n",
    "            variable named \"favorite colors\" and the possible answers are \"red\", \n",
    "            \"white\", and \"green\", then we will have three columns: \n",
    "                - \"favorite color | red\", \n",
    "                - \"favorite color | white\", and \n",
    "                - \"favorite color | green\"\n",
    "        \"\"\"\n",
    "        self._dummify_categorical_columns()\n",
    "        self._scale_single_choice_cat_columns()\n",
    "        self._scale_multi_choice_cat_columns()\n",
    "        self._scale_continuous_columns()\n",
    "        \n",
    "        return pd.concat(\n",
    "            [\n",
    "                self.single_choice_cat_columns,\n",
    "                self.multi_choice_cat_columns,\n",
    "                self.continuous_columns\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    def _dummify_categorical_columns(self):\n",
    "        self.multi_choice_cat_columns = pd.DataFrame()\n",
    "        self.single_choice_cat_columns = pd.DataFrame()\n",
    "        \n",
    "        for multi_choice_categorical_var_name in self.multi_choice_categorical_var_names:\n",
    "                \n",
    "            \n",
    "            self.multi_choice_cat_columns = pd.concat(\n",
    "                [\n",
    "                    self.multi_choice_cat_columns,\n",
    "                    self.data[multi_choice_categorical_var_name]\\\n",
    "                        .explode()\\\n",
    "                        .str\\\n",
    "                        .get_dummies()\\\n",
    "                        .sum(level=0)\\\n",
    "                        .add_prefix(multi_choice_categorical_var_name + ' | ')\n",
    "                ],\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "        for single_choice_categorical_var_name in self.single_choice_categorical_var_names:\n",
    "            self.single_choice_cat_columns = pd.concat(\n",
    "                [\n",
    "                    self.single_choice_cat_columns,\n",
    "                    pd.get_dummies(\n",
    "                        self.data[single_choice_categorical_var_name], \n",
    "                        prefix=single_choice_categorical_var_name, \n",
    "                        prefix_sep=' | '\n",
    "                    )\n",
    "                ],\n",
    "                axis=1\n",
    "            )\n",
    "    \n",
    "    def _scale_single_choice_cat_columns(self):\n",
    "        self.single_choice_cat_columns = self.single_choice_cat_columns * self.SINGLE_CHOICE_SCALER\n",
    "        \n",
    "    def _scale_multi_choice_cat_columns(self):        \n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        for multi_choice_categorical_var_name in self.multi_choice_categorical_var_names:\n",
    "            sub_columns = self.multi_choice_cat_columns.columns[\n",
    "                self\\\n",
    "                    .multi_choice_cat_columns\\\n",
    "                    .columns\\\n",
    "                    .str\\\n",
    "                    .contains(multi_choice_categorical_var_name + ' | ')\n",
    "            ]\n",
    "            \n",
    "            scaler = 1.0 / np.sqrt(len(sub_columns))\n",
    "            \n",
    "            df = pd.concat(\n",
    "                [\n",
    "                    df,\n",
    "                    self.multi_choice_cat_columns * scaler\n",
    "                ], \n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "        self.multi_choice_cat_columns = df\n",
    "        \n",
    "    def _scale_continuous_columns(self):\n",
    "        self.continuous_columns = \\\n",
    "            pd.DataFrame(\n",
    "                minmax_scale(\n",
    "                    self.data[self.continuous_var_names]\n",
    "                ), \n",
    "                columns=self.continuous_var_names\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_var_names = ['continuous']\n",
    "multi_choice_categorical_var_names = ['cat_2']\n",
    "single_choice_categorical_var_names = ['cat_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_1 | blue</th>\n",
       "      <th>cat_1 | red</th>\n",
       "      <th>cat_1 | white</th>\n",
       "      <th>cat_2 | a</th>\n",
       "      <th>cat_2 | b</th>\n",
       "      <th>cat_2 | c</th>\n",
       "      <th>continuous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.935169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat_1 | blue  cat_1 | red  cat_1 | white  cat_2 | a  cat_2 | b  cat_2 | c  \\\n",
       "0         0.000        0.707          0.000    0.57735    0.00000    0.00000   \n",
       "1         0.000        0.000          0.707    0.00000    0.57735    0.00000   \n",
       "2         0.707        0.000          0.000    0.57735    0.57735    0.57735   \n",
       "\n",
       "   continuous  \n",
       "0    0.935169  \n",
       "1    0.000000  \n",
       "2    1.000000  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = EuclideanDistanceDataPreprocessor(\n",
    "    continuous_var_names=continuous_var_names,\n",
    "    data=sample_df,\n",
    "    multi_choice_categorical_var_names=multi_choice_categorical_var_names,\n",
    "    single_choice_categorical_var_names=single_choice_categorical_var_names\n",
    ")\n",
    "\n",
    "preprocessor.preprocess()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
